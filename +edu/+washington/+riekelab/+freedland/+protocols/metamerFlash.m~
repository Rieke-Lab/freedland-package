% Replace a natural image with a metamer.
% By J. Freedland, 2019.
classdef metamerFlash < edu.washington.riekelab.protocols.RiekeLabStageProtocol
    properties
        % Stimulus timing
        preTime = 250   % in ms
        stimTime = 250  % in ms
        tailTime = 250  % in ms
        
        % Natural image trajectory
        referenceImageNo = 5;    % natural image number (1 to 101)
        referenceFrameNumber = 0;% specific frame in a eye movement trajectory. set to zero to be random.
        numberMetamers = 2;      % number of metamers to view
        numberAntiMetamers = 2;  % number of anti-metamers to view
        numberRandom = 1;        % number of random images to view
        randomizeTrials = true;  % whether to randomize presentations
        
        % Additional parameters
        onlineAnalysis = 'extracellular'
        numberOfAverages = uint16(5) % number of epochs to queue
        amp % Output amplifier
    end
    
    properties (Hidden)
        ampType
        onlineAnalysisType = symphonyui.core.PropertyType('char', 'row', {'none', 'extracellular', 'exc', 'inh'}) 
        backgroundIntensity
        imageMatrices
        trialOrder
        counter
    end

    methods
        
        function didSetRig(obj)
            didSetRig@edu.washington.riekelab.protocols.RiekeLabStageProtocol(obj);
            [obj.amp, obj.ampType] = obj.createDeviceNamesProperty('Amp');
        end

        function prepareRun(obj)

            prepareRun@edu.washington.riekelab.protocols.RiekeLabStageProtocol(obj);

            obj.showFigure('symphonyui.builtin.figures.ResponseFigure', obj.rig.getDevice(obj.amp));
            obj.showFigure('edu.washington.riekelab.freedland.figures.MeanResponseFigure',...
                obj.rig.getDevice(obj.amp),'recordingType',obj.onlineAnalysis,'splitEpoch',2); 
            obj.showFigure('edu.washington.riekelab.freedland.figures.FrameTimingFigure',...
                obj.rig.getDevice('Stage'), obj.rig.getDevice('Frame Monitor'));
            
            % load metamer information
            filename = '+edu/+washington/+riekelab/+freedland/+images/metamerData.mat';
            load(filename)
            
            % adjust reference frame if needed.
            if obj.referenceFrameNumber == 0
                obj.referenceFrameNumber = randperm(1000);
                obj.referenceFrameNumber = obj.frameNumber(1);
            end
            
            % from analysis file, pull relevant frame and image information
            A = totalBest{obj.frameNumber, obj.referenceImageNo};
            B = totalWorst{obj.frameNumber, obj.referenceImageNo};
            
            % arrange
            metamerInfo = A(1:obj.numberMetamers,2:3); % sorted from best to least best
            antiMetamerInfo = B(end-(obj.numberAntiMetamers-1):end,2:3); % sorted from worst to least worst
            a = randperm(101); % images
            b = randperm(1000); % frames
            randomImgInfo = [a(1:obj.numberRandom)' b(1:obj.numberRandom)'];
            
            % produce alternative images
            obj.imageMatrices = produceImage(obj,metamerInfo,antiMetamerInfo,randomImgInfo);
            
            if obj.randomizeTrials == true
                obj.trialOrder = randperm(size(obj.
                
                
        end
        
        function prepareEpoch(obj, epoch)
            
            prepareEpoch@edu.washington.riekelab.protocols.RiekeLabStageProtocol(obj, epoch);
            device = obj.rig.getDevice(obj.amp);
            duration = (obj.preTime + obj.stimTime + obj.tailTime) / 1e3;
            
            epoch.addDirectCurrentStimulus(device, device.background, duration, obj.sampleRate);
            epoch.addResponse(device);
            epoch.addParameter('backgroundIntensity', obj.backgroundIntensity);
            
            % Add metadata from Stage, makes analysis easier.
            epoch.addParameter('canvasSize',obj.rig.getDevice('Stage').getConfigurationSetting('canvasSize'));
            epoch.addParameter('micronsPerPixel',obj.rig.getDevice('Stage').getConfigurationSetting('micronsPerPixel'));
            epoch.addParameter('monitorRefreshRate',obj.rig.getDevice('Stage').getConfigurationSetting('monitorRefreshRate'));
            epoch.addParameter('centerOffset',obj.rig.getDevice('Stage').getConfigurationSetting('centerOffset')); % in pixels
        end
        
        function p = createPresentation(obj)
            
            canvasSize = obj.rig.getDevice('Stage').getCanvasSize();             
            p = stage.core.Presentation((obj.preTime + obj.stimTime + obj.tailTime) * 1e-3);

            % Set background intensity
            p.setBackgroundColor(obj.backgroundIntensity);
            
            % Prep to display image
            scene1 = stage.builtin.stimuli.Image(obj.imageMatrix);
            scene2 = stage.builtin.stimuli.Image(obj.imageMatrix2);
            scene1.size = [size(obj.imageMatrix,2) * 3.3/obj.rig.getDevice('Stage').getConfigurationSetting('micronsPerPixel'),...
                size(obj.imageMatrix,1) * 3.3/obj.rig.getDevice('Stage').getConfigurationSetting('micronsPerPixel')];
            scene2.size = scene1.size;
            p0 = canvasSize/2;
            scene1.position = p0;
            scene2.position = p0;
            
            % Use linear interpolation when scaling the image
            scene1.setMinFunction(GL.LINEAR);
            scene1.setMagFunction(GL.LINEAR);
            scene2.setMinFunction(GL.LINEAR);
            scene2.setMagFunction(GL.LINEAR);
            
            p.addStimulus(scene1);
            p.addStimulus(scene2);
            
            % Apply eye trajectories to move image around.
            cycleTime = (obj.preTime + obj.stimTime + obj.tailTime) / 1e3;

            scene1Visible = stage.builtin.controllers.PropertyController(scene1, 'visible', ...
                @(state)state.time >= obj.preTime * 1e-3 && state.time < (obj.preTime + obj.stimTime) * 1e-3);
            scene2Visible = stage.builtin.controllers.PropertyController(scene2, 'visible', ...
                @(state)state.time-cycleTime >= obj.preTime * 1e-3 && state.time-cycleTime < (obj.preTime + obj.stimTime) * 1e-3);
            p.addController(scene1Visible);
            p.addController(scene2Visible);
            
            % Apply far-surround mask
            surround = stage.builtin.stimuli.Rectangle();
            surround.position = canvasSize/2;
            surround.size = [2*canvasSize(1) 2*canvasSize(2)];
            surround.color = obj.backgroundIntensity;
            annulusS = uint8(obj.surroundMask*255);
            surroundMaskX = stage.core.Mask(annulusS);
            surround.setMask(surroundMaskX);
            p.addStimulus(surround);
            
        end
        
        function outputImages = produceImage(obj,metamers,antiMetamers,randomImgInfo)
            
            imageNumbs = [obj.referenceImageNo; metamers(:,1); antiMetamers(:,1); randomImgInfo(:,1)];
            frameNumbs = [obj.referenceFrameNumber; metamers(:,2); antiMetamers(:,2); randomImgInfo(:,2)];
            
            canvasSize = obj.rig.getDevice('Stage').getCanvasSize();
            imgSize = ceil(canvasSize / (3.3/obj.rig.getDevice('Stage').getConfigurationSetting('micronsPerPixel')));
            xRange = floor(imgSize(1) / 2);
            yRange = floor(imgSize(2) / 2);
            centering = obj.rig.getDevice('Stage').getConfigurationSetting('centerOffset'); % in mu
            centeringPix = centering ./ (3.3/obj.rig.getDevice('Stage').getConfigurationSetting('micronsPerPixel'));
            
            outputImages = zeros(imgSize(2),imgSize(1),size(imageNumbs,1));
 
            for a = 1:size(imageNumbs,1)
                imageVal = imageNumbs(a,1);
                frameVal = frameNumbs(a,1);
                [~, baseMovement, fixMovement, pictureInformation] = edu.washington.riekelab.freedland.scripts.pathDOVES(imageVal, 1,...
                        'amplification', 1,'mirroring', true);
                    
                img = pictureInformation.image;
                img = img./max(img(:)) .* 255;
                
                if a == 1
                    obj.backgroundIntensity = mean(img(:));
                end
                
                xTraj = baseMovement.x(frameVal) + fixMovement.x(frameVal);
                yTraj = baseMovement.y(frameVal) + fixMovement.y(frameVal);

                % while the rig automatically centers the stimulus, our
                % calculation doesn't.
                centeredXTraj = round(xTraj - centeringPix(1));
                centeredYTraj = round(yTraj + centeringPix(2));

                % create image
                outputImages(:,:,a) = img(centeredYTraj-yRange:centeredYTraj+yRange-1,...
                    centeredXTraj-xRange:centeredXTraj+xRange-1); 
            end
        end 
        
        function tf = shouldContinuePreparingEpochs(obj)
            tf = obj.numEpochsPrepared < obj.numberOfAverages;
        end
        
        function tf = shouldContinueRun(obj)
            tf = obj.numEpochsCompleted < obj.numberOfAverages;
        end
    end
end